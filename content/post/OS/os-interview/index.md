---
title: "操作系统"
date: 2025-03-04T10:46:33+08:00
draft: false
categories: ["八股","操作系统"]
tags: ["os","虚拟内存", "文件系统", "多线程","操作系统"]
math: true
---

![操作系统-image-1](images/操作系统-image-1.png)

## OS 基础

###  什么是操作系统

- 操作系统（Operating System，简称 OS）是管理计算机硬件与软件资源的程序，是计算机的管理员
- 操作系统**本质上是一个运行在计算机上的软件程序** ，主要用于管理计算机硬件和软件资源
- 操作系统存在屏蔽了硬件层的复杂性。 *没有什么问题是加一个中间层无法解决的*, os 就是硬件和应用程序的中间层
- 操作系统的 **内核(Kernel)** 是操作系统的核心部分，它负责系统的**内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理**。内核是连接应用程序和硬件的桥梁，决定着系统的性能和稳定性。

![操作系统-image-2](images/操作系统-image-2.png)

### 操作系统有哪些功能

从资源管理的角度来看，操作系统有 6 大功能：

1. **进程和线程的管理**：进程的创建、撤销、阻塞、唤醒，进程间的通信等。
2. **存储管理**：内存的分配和管理、外存（磁盘等）的分配和管理等。
3. **文件管理**：文件的读、写、创建及删除等。
4. **设备管理**：完成设备（输入输出设备和外部存储设备等）的请求或释放，以及设备启动等功能。
5. **网络管理**：操作系统负责管理计算机网络的使用
6. **安全管理**：用户的身份认证、访问控制、文件加密等，以防止非法用户对系统资源的访问和操作。

### 用户态和内核态

> 什么是用户态和内核态

根据进程对资源的访问权限，我们可以把进程在系统上的运行分为两个级别：

- **用户态(User Mode)** : 用户态运行的进程可以直接读取用户程序的数据，拥有较低的权限。当应用程序需要执行某些需要**特殊权限**的操作，例如读写磁盘、网络通信等，就需要向操作系统发起系统调用请求，进入内核态。
- **内核态(Kernel Mode)**：内核态运行的进程几乎可以访问计算机的任何资源包括系统的内存空间、设备、驱动程序等，不受限制，拥有非常高的权限。当操作系统接收到进程的系统调用请求时，就会从用户态切换到内核态，执行相应的系统调用，并将结果返回给进程，最后再从内核态切换回用户态。

> 为什么要用用户态和内核态? 只有内核态不行吗

- 在 **CPU 的所有指令**中，有一些指令是比较**危险**的比如内存分配、设置时钟、IO 处理等，叫做特权指令. 我们不希望每个用户都可以执行这些指令

> PS: syscall 不是函数, 而是汇编意义上的指令

- 如果计算机系统中只有一个内核态，那么所有程序或进程都必须共享系统资源，例如内存、CPU、硬盘等，这将导致系统资源的竞争和冲突，从而影响系统性能和效率。并且，这样也会让系统的安全性降低，毕竟所有程序或进程都具有相同的特权级别和访问权限。

> ==用户态和内核态如何切换==

![操作系统-image-3](images/操作系统-image-3.png)

用户态切换到内核态的 3 种方式：

1. **系统调用（Trap）**：用户态进程 **主动** 要求切换到内核态的一种方式，主要是为了使用内核态才能做的事情比如读取磁盘资源。
2. **中断（Interrupt）**：来自外部的打断, 比如时间片轮转的计时器, 或者 dma 在处理完成文件传输后会给 cpu 一个中断
3. **异常（Exception）**：**来自程序内部的事先不可知的异常**，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

### 系统调用

> 什么是系统调用?

![操作系统-image-4](images/操作系统-image-4.png)

当用户态的程序想要执行 os 提供的功能时, 就需要通过 `trap` 执行系统调用

也就是说在我们运行的用户程序中，凡是与**系统态级别的资源有关的操作**（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

> 系统调用的过程了解吗

![操作系统-image-5](images/操作系统-image-5.png)

系统调用的过程可以简单分为以下几个步骤：

1. 用户态的程序执行到**特权指令**比如 `open`, `write`, `malloc` 之类的，用户态程序权限不足，因此会中断执行，也就是 **Trap**
2. 发生中断后，当前 CPU 执行的程序会中断，进入内核态, 跳转到中断处理程序(handler)。内核程序开始执行，也就是开始处理系统调用。
3. 内核处理完成后，主动触发 Trap，这样会再次发生中断，切换回用户态工作。

## 进程和线程

### 概念

> 什么是进程和线程

- **进程（Process）** 是指计**算机中正在运行的一个程序实例**。举例：你打开的微信就是一个进程。
- **线程（Thread）** 也被称为轻量级进程，更加轻量。多个线程可以在同一个进程中同时执行，并且共享进程的资源. 
- **线程是程序执行的最小单元**


> 进程与线程的区别

![操作系统-image-6](images/操作系统-image-6.png)

从上图可以看出：一个进程中可以有多个线程，多个线程共享进程的**堆**和**方法区 (JDK1.8 之后的元空间)** 资源，但是每个线程有自己的**程序计数器**、**虚拟机栈** 和 **本地方法栈**。

- 线程是进程划分成的更小的运行单位,一个进程在其执行的过程中可以产生多个线程。
- 进程是 os 提供的隔离和保护的最小单元, 线程是程序执行的最小单元, 是一个个指令流
- 线程执行开销小，但不利于资源的管理和保护；而进程正相反。


> 有了进程为什么还需要线程

- 进程切换是一个开销很大的操作，线程切换的成本较低。
- 线程更轻量，一个进程可以创建多个线程。
- 多个线程可以并发处理不同的任务，更有效地利用了多处理器和多核计算机。而单线程的进程只能在一个时间干一件事，如果在执行过程中遇到阻塞问题比如 IO 阻塞就会挂起直到结果返回。
- 同一进程内的线程**共享内存和文件**，因此它们之间相互通信无须调用内核。

> 为什么要用多线程

- **从计算机底层来说：** 线程可以比作是轻量级的进程，是程序执行的最小单位,线程间的切换和调度的成本远远小于进程。另外，多核 CPU 时代意味着多个线程可以同时运行，这**减少了线程上下文切换的开销**。
- 多线程并发编程正是**开发高并发系统的基础**，利用好多线程机制可以大大提高系统整体的并发能力以及性能。
- 减少了单线程程序被阻塞所占用的时间, **提高了 java 进程对系统资源的利用率**
- 当前 cpu 的核心频率由于技术问题难以提升, 所以通过增加 cpu 核心数量来提升性能. 只有多线程才能提高对计算机硬件的利用

> 线程间同步的方式

线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。

- **互斥锁(Mutex)** 
- **读写锁（Read-Write Lock）**
- **信号量(Semaphore)** 
- **屏障（Barrier）** 
- **事件(Event)**

> PCB 是什么? 包含哪些信息

**PCB（Process Control Block）** 即进程控制块，是操作系统中用来管理和跟踪进程的数据结构，每个进程都对应着一个独立的 PCB。你可以将 PCB 视为进程的大脑。

当操作系统创建一个新进程时，会为该进程分配一个唯一的 PID，并且为该进程创建一个对应的进程控制块。当进程执行时，PCB 中的信息会不断变化，操作系统会根据这些信息来管理和调度进程。

PCB 主要包含下面几部分的内容：

- 进程的**描述信息**，包括进程的名称、标识符等等；
- 进程的**调度信息**，包括进程阻塞原因、进程状态（就绪、运行、阻塞等）、进程优先级（标识进程的重要程度）等等；
- 进程对**资源的需求情况**，包括 CPU 时间、内存空间、I/O 设备等等。
- 进程**打开的文件信息**，包括文件描述符、文件类型、打开模式等等。
- **处理机的状态信息**（由处理机的各种寄存器中的内容组成的），包括通用寄存器、指令计数器、程序状态字 PSW、用户栈指针

### 进程调度

> 进程有哪几种状态

![操作系统-image-7](images/操作系统-image-7.png)

我们一般把进程大致分为 5 种状态，这一点和线程很像！

- **创建状态(new)**：进程正在被创建，尚未到就绪状态。
- **就绪状态(ready)**：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
- **运行状态(running)**：进程正在处理器上运行
- **阻塞状态(waiting)**：又称为等待状态，进程正在等待某一事件而暂停运行
- **结束状态(terminated)**：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

> 进程间的通信方式有哪些?

- **管道/匿名管道(Pipes)** ：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。
- **有名管道(Named Pipes)** : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循 **先进先出(First In First Out)** 。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。
- **信号(Signal)** ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；
- **消息队列(Message Queuing)** ：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。存放于内核中
- **信号量(Semaphores)** ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。
- **共享内存(Shared memory)** ：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是**最有用的进程间通信方式**。
- **套接字(Sockets)** : 此方法主要用于在客户端和服务器之间通过网络进行通信。

> 进程的调度算法有哪些

![操作系统-image-8](images/操作系统-image-8.png)

这是一个很重要的知识点！为了确定首先执行哪个进程以及最后执行哪个进程以实现最大 CPU 利用率，计算机科学家已经定义了一些算法，它们是：

- **先到先服务调度算法(FCFS，First Come, First Served)** : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **短作业优先的调度算法(SJF，Shortest Job First)** : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度
-  **时间片轮转调度算法（RR，Round-Robin）** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
- **多级反馈队列调度算法（MFQ，Multi-level Feedback Queue）**：多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。
- **优先级调度算法（Priority）**：为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

> 什么是僵尸进程和孤儿进程

在 Unix/Linux 系统中，子进程通常是通过 fork()系统调用创建的，该调用会创建一个新的进程，该进程是原有进程的一个副本。子进程和父进程的运行是相互独立的，它们各自拥有自己的 PCB，即使父进程结束了，子进程仍然可以继续运行。

当一个进程调用 exit()系统调用结束自己的生命时，内核会释放该进程的所有资源，包括打开的文件、占用的内存等，但是该进程对应的 PCB 依然存在于系统中。这些信息只有在父进程调用 wait()或 waitpid()系统调用时才会被释放，以便让父进程得到子进程的状态信息。



- **僵尸进程**：子进程已经终止，但是其父进程仍在运行，且父进程没有调用 wait()或 waitpid()等系统调用来获取子进程的状态信息，释放子进程占用的资源，导致子进程的 PCB 依然存在于系统中，但无法被进一步使用。这种情况下，子进程被称为“僵尸进程”。避免僵尸进程的产生，父进程需要及时调用 wait()或 waitpid()系统调用来回收子进程。
- **孤儿进程**：一个进程的父进程已经终止或者不存在，但是该进程仍在运行。这种情况下，该进程就是孤儿进程。孤儿进程通常是由于父进程意外终止或未及时调用 wait()或 waitpid()等系统调用来回收子进程导致的。为了避免孤儿进程占用系统资源，操作系统会将孤儿进程的父进程设置为 init 进程（进程号为 1），由 init 进程来回收孤儿进程的资源。

> 如何查看僵尸进程

`top` 命令

![操作系统-image-9](images/操作系统-image-9.png)
### 死锁

> 什么是死锁

死锁（Deadlock）描述的是这样一种情况：多个进程/线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于进程/线程被无限期地阻塞，因此程序不可能正常终止。

> 举一个操作系统发生死锁的例子

假设有两个进程 A 和 B，以及两个资源 X 和 Y，它们的分配情况如下：

|进程|占用资源|需求资源|
|---|---|---|
|A|X|Y|
|B|Y|X|

此时，进程 A 占用资源 X 并且请求资源 Y，而进程 B 已经占用了资源 Y 并请求资源 X。两个进程都在等待对方释放资源，无法继续执行，陷入了死锁状态。

> 产生死锁的四个**必要条件**

- **互斥**：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。
- **占有并等待**：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。
- **非抢占**：资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。
- **循环等待**：有一组等待进程 `{P0, P1,..., Pn}`， `P0` 等待的资源被 `P1` 占有，`P1` 等待的资源被 `P2` 占有，……，`Pn-1` 等待的资源被 `Pn` 占有，`Pn` 等待的资源被 `P0` 占有。

> 模拟死锁

![操作系统-image-10](images/操作系统-image-10.png)

```java
public class DeadLockDemo {
    private static Object resource1 = new Object();//资源 1
    private static Object resource2 = new Object();//资源 2

    public static void main(String[] args) {
        new Thread(() -> {
            synchronized (resource1) {
                System.out.println(Thread.currentThread() + "get resource1");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + "waiting get resource2");
                synchronized (resource2) {
                    System.out.println(Thread.currentThread() + "get resource2");
                }
            }
        }, "线程 1").start();

        new Thread(() -> {
            synchronized (resource2) {
                System.out.println(Thread.currentThread() + "get resource2");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + "waiting get resource1");
                synchronized (resource1) {
                    System.out.println(Thread.currentThread() + "get resource1");
                }
            }
        }, "线程 2").start();
    }
}
```

> 死锁的解决方案

思路: **破坏四个必要条件, 一般考虑破坏 2,4, 占有并等待和非抢占**

**死锁的预防**

**1、静态分配策略**

静态分配策略可以破坏死锁产生的**第二个条件**（占有并等待）。所谓静态分配策略，就是指**一个进程必须在执行前就申请到它所需要的全部资源，并且知道它所要的资源都得到满足之后才开始执行**。进程要么占有所有的资源然后开始执行，要么不占有资源，不会出现占有一些资源等待一些资源的情况。

静态分配策略逻辑简单，实现也很容易，但这种策略 **严重地降低了资源利用率**，因为在每个进程所占有的资源中，有些资源是在比较靠后的执行时间里采用的，甚至有些资源是在额外的情况下才使用的，这样就可能造成一个进程占有了一些 **几乎不用的资源而使其他需要该资源的进程产生等待** 的情况。

**2、层次分配策略**

层次分配策略破坏了产生死锁的第四个条件(循环等待)。在层次分配策略下，所有的资源被分成了多个层次，**一个进程得到某一次的一个资源后，它只能再申请较高一层的资源；当一个进程要释放某层的一个资源时，必须先释放所占用的较高层的资源**，按这种策略，是**不可能出现循环等待链**的，因为那样的话，就出现了已经申请了较高层的资源，反而去申请了较低层的资源，不符合层次分配策略，证明略。

**死锁的避免**

上面提到的 **破坏** 死锁产生的四个必要条件之一就可以成功 **预防系统发生死锁** ，但是会导致 **低效的进程运行** 和 **资源使用率** 。而死锁的避免相反，它的角度是允许系统中**同时存在四个必要条件** ，只要掌握并发进程中与每个进程有关的资源动态申请情况，做出 **明智和合理的选择** ，仍然可以避免死锁，因为四大条件仅仅是产生死锁的必要条件。

我们将系统的状态分为 **安全状态** 和 **不安全状态** ，每当在为申请者分配资源前先测试系统状态，若把系统资源分配给申请者会产生死锁，则拒绝分配，否则接受申请，并为它分配资源。比如银行家算法

**死锁的解除**

当死锁检测程序检测到存在死锁发生时，应设法让其解除，让系统从死锁状态中恢复过来，常用的解除死锁的方法有以下四种：

1. **立即结束所有进程的执行，重新启动操作系统**：这种方法简单，但以前所在的工作全部作废，损失很大。
2. **撤销涉及死锁的所有进程，解除死锁后继续运行**：这种方法能彻底打破**死锁的循环等待**条件，但将付出很大代价，例如有些进程可能已经计算了很长时间，由于被撤销而使产生的部分结果也被消除了，再重新执行时还要再次进行计算。
3. **逐个撤销涉及死锁的进程，回收其资源直至死锁解除。**
4. **抢占资源**：从涉及死锁的一个或几个进程中抢占资源，把夺得的资源再分配给涉及死锁的进程直至死锁解除。

## 内存管理

### 概念

> 内存管理做了什么?

![操作系统-image-11](images/操作系统-image-11.png)

操作系统的内存管理非常重要，主要负责下面这些事情：

- **内存的分配与回收**：对进程所需的内存进行分配和释放，malloc 函数：申请内存，free 函数：释放内存。
- **地址转换**：将程序中的虚拟地址转换成内存中的物理地址。
- **内存扩充**：**让每个程序认为自己拥有无限大的内存**, 必要时对内存空间阔欧容
- **内存映射**：将一个文件直接映射到进程的进程空间中，这样可以通过内存指针用读写内存的办法直接存取文件内容，速度更快。
- **内存优化**：通过调整内存分配策略和回收算法来优化内存使用效率。
- **内存隔离**：**让每个程序认为自己独享整个内存空间**, 保证进程之间使用内存互不干扰，避免一些恶意程序通过修改内存来破坏系统的安全性。

> 什么是内存碎片

内存碎片是由内存的申请和释放产生的，通常分为下面两种：

![操作系统-image-12](images/操作系统-image-12.png)

- **内部内存碎片(Internal Memory Fragmentation，简称为内存碎片)**：已经分配给进程使用但未被使用的内存。导致内部内存碎片的主要原因是，**当采用固定比例比如 2 的幂次方进行内存分配时，进程所分配的内存可能会比其实际所需要的大**。举个例子，一个进程只需要 65 字节的内存，但为其分配了 128（2^7） 大小的内存，那 63 字节的内存就成为了内部内存碎片。
- **外部内存碎片(External Memory Fragmentation，简称为外部碎片)**：由于未分配的连续内存区域太小，以至于不能满足任意进程所需要的内存分配请求，这些小片段且不连续的内存空间被称为外部碎片。也就是说，**外部内存碎片指的是那些并未分配给进程但又不能使用的内存**。我们后面介绍的分段机制就会导致外部内存碎片。

> 常见的内存管理方式

内存管理方式可以简单分为下面两种：

- **连续内存管理**：为一个用户程序分配一个连续的内存空间，内存利用率一般不高。
- **非连续内存管理**：允许一个程序使用的内存分布在离散或者说不相邻的内存中，相对更加灵活一些。


连续内存管理:

**块式管理** 是早期计算机操作系统的一种连续内存管理方式，存在严重的内存碎片问题。

在 Linux 系统中，连续内存管理采用了 **伙伴系统（Buddy System）算法** 来实现，基本思想是把内存区域划分为 2 的幂次的 buddy 单元, 然后分配内存时使用二分法, 找到最小的大小合适的单元

但是这个方法无法解决内部碎片问题, Linux 通过 SLAB 解决了内部碎片问题

非连续内存管理:

非连续内存管理存在下面 3 种方式：

- **段式管理**：以段(一段连续的物理内存)的形式管理/分配物理内存。应用程序的虚拟地址空间被分为大小不等的段，段是有实际意义的
- **页式管理**：把物理内存分为连续等长的物理页，应用程序的虚拟地址空间也被划分为连续等长的虚拟页，是现代操作系统广泛使用的一种内存管理方式。
- **段页式管理机制**：结合了段式管理和页式管理的一种内存管理机制，把物理内存**先分成若干段**，每个段又继续分成若干大小相等的页

### 虚拟内存

> 什么是虚拟内存, 有什么用?

![操作系统-image-13](images/操作系统-image-13.png)

**虚拟内存(Virtual Memory)** 是计算机系统内存管理非常重要的一个技术，本质上来说它只是逻辑存在的，是一个假想出来的内存空间，主要作用是作为进程访问主存（物理内存）的桥梁并简化内存管理。

总的来说, 虚拟内存提供了以下功能

- **隔离进程**：物理内存通过虚拟地址空间访问，虚拟地址空间与进程一一对应。每个进程都认为自己拥有了整个物理内存，进程之间彼此隔离
- **提升物理内存利用率**：有了虚拟地址空间后，操作系统只需要将进程当前正在使用的部分数据或指令加载入物理内存。
- **简化内存管理**：进程都有一个一致且私有的虚拟地址空间，程序员不用和真正的物理内存打交道，而是借助虚拟地址空间访问物理内存，从而简化了内存管理。
- **多个进程共享物理内存**：多程序共享动态链接库
- **提高内存使用安全性**：控制进程对物理内存的访问，隔离不同进程的访问权限，提高系统的安全性。
- **提供更大的可使用内存空间**：让每个程序**认为自己有几乎无限大的可用内存**, 必要时交换硬盘中的数据到内存中

> 什么是虚拟地址和物理地址

**物理地址（Physical Address）** 是真正的物理内存中地址，更具体点来说是内存阵列上的单元索引. 每个程序中访问的内存都是**虚拟地址（Virtual Address）**

操作系统一般通过 CPU 芯片中的一个重要组件 **MMU(Memory Management Unit，内存管理单元)** 将虚拟地址转换为物理地址，这个过程被称为 **地址翻译/地址转换（Address Translation）** 。

![操作系统-image-14](images/操作系统-image-14.png)

通过 MMU 将虚拟地址转换为物理地址后，再通过总线传到物理内存设备，进而完成相应的物理内存读写请求。

MMU 将虚拟地址翻译为物理地址的主要机制有两种: **分段机制** 和 **分页机制**

> 什么是虚拟地址空间和物理地址空间？

- 虚拟地址空间是虚拟地址的集合，是虚拟内存的范围。每一个进程都有一个**一致且私有**的虚拟地址空间。
- 物理地址空间是物理地址的集合，是物理内存的范围。

> 虚拟地址和物理内存地址如何映射

MMU 将虚拟地址翻译为物理地址的主要机制有 3 种:

1. 分段机制
2. 分页机制
3. 段页机制

其中，现代操作系统广泛采用分页机制

### 分段机制

**分段机制（Segmentation）** 以段(一段 **连续** 的物理内存)的形式管理/分配物理内存。应用程序的虚拟地址空间被分为大小不等的段，段是有实际意义的，每个段定义了一组逻辑信息，例如有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等

> 段表有什么用? 地址翻译过程是怎么样的?

分段管理通过 **段表（Segment Table）** 映射虚拟地址和物理地址。

分段机制下的虚拟地址由两部分组成：

- **段表索引**：标识着该虚拟地址属于整个虚拟地址空间中的哪一个段。
- **段内偏移量**：相对于该段起始地址的偏移量。

具体的地址翻译过程如下：

![操作系统-image-15](images/操作系统-image-15.png)

1. MMU 首先解析得到虚拟地址中的段号；
2. 通过段号去该应用程序的段表中取出对应的段信息（找到对应的段表项）；
3. 从段信息中取出该段的起始地址（物理地址）加上虚拟地址中的段内偏移量得到最终的物理地址。

段表中还存有诸如段长(可用于检查虚拟地址是否超出合法范围)、段类型（该段的类型，例如代码段、数据段等）等信息。

**通过段号一定要找到对应的段表项吗？得到最终的物理地址后对应的物理内存一定存在吗？**

不一定。段表项可能并不存在：

- **段表项被删除**：软件错误、软件恶意行为等情况可能会导致段表项被删除。
- **段表项还未创建**：如果系统内存不足或者无法分配到连续的物理内存块就会导致段表项无法被创建。

> 分段机制为什么会导致内存外部碎片

![操作系统-image-16](images/操作系统-image-16.png)

分段机制容易出现外部内存碎片，即在段与段之间留下碎片空间, 是因为**分段机制维护了地址的起始和索引, 这要求物理内存的连续性**, 但是进程开启和关闭, 内存重新分配会破坏内存的连续性

### 分页机制

**分页机制（Paging）** 把主存（物理内存）分为连续等长的物理页，应用程序的虚拟地址空间划也被分为连续等长的虚拟页。现代操作系统广泛采用分页机制。

![操作系统-image-17](images/操作系统-image-17.png)

> 页表有什么用? 地址翻译过程是怎么样的?

分页机制下的虚拟地址由两部分组成：

- **页号**：通过虚拟页号可以从页表中取出对应的物理页号；
- **页内偏移量**：物理页起始地址+页内偏移量=物理内存地址。

**可见, 页表维护了虚拟页和物理页的映射关系**

具体的地址翻译过程如下：

1. MMU 首先解析得到虚拟地址中的虚拟页号；
2. 通过虚拟页号去该应用程序的页表中取出对应的物理页号（找到对应的页表项）；
3. 用该物理页号对应的物理页起始地址（物理地址）加上虚拟地址中的页内偏移量得到最终的物理地址。

页表中还存有诸如访问标志（标识该页面有没有被访问过）、脏数据标识位等信息。

**通过虚拟页号一定要找到对应的物理页号吗？找到了物理页号得到最终的物理地址后对应的物理页一定存在吗？**

不一定！可能会存在 **页缺失** 。也就是说，物理内存中没有对应的物理页或者物理内存中有对应的物理页但虚拟页还未和物理页建立映射（对应的页表项不存在）。或者内存不足, 对应的页被**交换到磁盘里**

> 单级页表有什么问题? 为什么需要多级页表?

常见的页表大小是 4kb, 一个 32 位地址空间需要 $2^{20}$ 个页表条目, 每一个条目是 4byte, 那么每个程序就需要 4mb!

为了解决这个问题，操作系统引入了 **多级页表** ，多级页表对应多个页表，每个页表与前一个页表相关联。32 位系统一般为二级页表，64 位系统一般为四级页表。

**在一个地址空间中大部分空间我们都是没有使用的**, 所以一级页面很多条目为空, 这就大大降低了内存

![操作系统-image-18](images/操作系统-image-18.png)

*多级页表属于时间换空间的典型场景，利用增加页表查询的次数减少页表占用的空间。*

> TLB 有什么用? 使用 TLB 之后地址翻译流程是怎样的

目前的问题是: **内存翻译太慢了**

![操作系统-image-19](images/操作系统-image-19.png)

有了多级页表之后, 我们需要多次去访问内存才能查询出物理内存, **但是内存对于 cpu 来说太慢了**, 于是引入了 TLB

TLB 是一块**全相联的SRAM 高速缓存**, 这意味着其有着极高的随机访存能力. 他被用作页表的 cache.

![操作系统-image-20](images/操作系统-image-20.png)

有了 TLB 之后, 我们先去 TLB 里查询

![操作系统-image-21](images/操作系统-image-21.png)

1. 从虚拟地址提取 TLB Tag 和 Index
2. 在 TLB 中查找
3. 如果命中：
   - 直接获取 PPN
   - 与 Page Offset 组合形成物理地址
4. 如果未命中：
   - 需要查询页表

> 什么是 Page fault?

页缺失指的是当软件试图访问已映射在虚拟地址空间中，但是目前并未被加载在物理内存中的一个分页时，由 MMU 所发出的中断。

常见的页缺失有下面这两种：

- **硬性页缺失（Hard Page Fault）**：虚拟内存空间中的虚拟页尚未分配物理页
- **软性页缺失（Soft Page Fault）**：物理内存中有对应的物理页，但虚拟页还未和物理页建立映射。可能由于被替换或尚未加载.

Page Fault 由对应的 handler 处理

发生上面这两种缺页错误的时候，应用程序访问的是有效的物理内存，只是出现了物理页缺失或者虚拟页和物理页的映射关系未建立的问题。如果应用程序访问的是无效的物理内存的话，还会出现 **无效缺页错误（Invalid Page Fault）** 。

> 常见的页面置换算法有哪些?

![操作系统-image-22](images/操作系统-image-22.png)

- **最佳页面置换算法（OPT，Optimal）**：优先选择淘汰的页面是以后永不使用的，或者是在最长时间内不再被访问的页面，理论最优, 实际无法实现
- **先进先出页面置换算法（FIFO，First In First Out）** : 最简单的一种页面置换算法，总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。该算法易于实现和理解，一般只需要通过一个 FIFO 队列即可满足需求。不过，它的性能并不是很好。
- **最近最久未使用页面置换算法（LRU ，Least Recently Used）**：LRU 算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。LRU 算法是根据各页之前的访问情况来实现，因此是易于实现的。
- **最少使用页面置换算法（LFU，Least Frequently Used）** : 和 LRU 算法比较像，不过该置换算法选择的是之前一段时间内使用最少的页面作为淘汰页。
- **时钟页面置换算法（Clock）**：可以认为是一种最近未使用算法，即逐出的页面都是最近没有使用的那个。

> 为何 Fifo 性能不好?

- **经常访问或者需要长期存在的页面会被频繁调入调出**：较早调入的页往往是经常被访问或者需要长期存在的页，这些页会被反复调入和调出。
- **存在 Belady 现象**：被置换的页面并不是进程不会访问的，有时就会出现分配的页面数增多但缺页率反而提高的异常现象。

> 哪种页面置换算法用的多?

LRU

> 分页机制和分段机制有哪些共同点?

**共同点**：

- 都是非连续内存管理的方式。
- 都采用了地址映射的方法，将虚拟地址映射到物理地址，以实现对内存的管理和保护。

**区别**：

- **分页机制以页面为单位进行内存管理，而分段机制以段为单位进行内存管理**。页的大小是固定的，通常为 2 的幂次方。而段的大小不固定。
- **页是物理单位**，即操作系统将物理内存划分成固定大小的页面，每个页面的大小通常是 2 的幂次方，例如 4KB、8KB 等等。而**段则是逻辑单位**，是为了满足程序对内存空间的逻辑需求而设计的，通常根据程序中数据和代码的逻辑结构来划分。
- **分段机制容易出现外部内存碎片**，即在段与段之间留下碎片空间(不足以映射给虚拟地址空间中的段)。**分页机制解决了外部内存碎片的问题，但仍然可能会出现内部内存碎片**。

### 段页机制

结合了段式管理和页式管理的一种内存管理机制，把物理内存先分成若干段，每个段又继续分成若干大小相等的页。

在段页式机制下，地址翻译的过程分为两个步骤：

1. 段式地址映射。
2. 页式地址映射。

### Locality

**局部性原理**是指程序在执行过程中倾向于重复访问最近使用过的数据或指令，或访问附近的数据，这一现象使得缓存和预取技术能够显著提升系统性能。

- **时间局部性**：由于程序中存在一定的循环或者重复操作，因此会反复访问同一个页或一些特定的页，这就体现了时间局部性的特点。
- **空间局部性**：由于程序中数据和指令的访问通常是具有一定的空间连续性的，因此当访问某个页时，往往会顺带访问其相邻的一些页。

## 文件系统

### 基本组成

文件系统是操作系统负责持久化存储数据的子系统, 基本单位是文件.

Linux 最经典的一句话是：「**一切皆文件**」，不仅普通的文件和目录，就连块设备、管道、socket 等，也都是统一交给文件系统管理的。

Linux 文件系统会为每个文件分配两个数据结构：**索引节点（_index node_）和目录项（_directory entry_）**，它们主要用来记录文件的元信息和目录层次结构。

- 索引节点，也就是 `inode`，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、**数据在磁盘的位置**等等。索引节点是文件的**唯一**标识，它们之间一一对应，也同样都会被存储在硬盘中，所以**索引节点同样占用磁盘空间**。
- 目录项，也就是 `dentry`，用来记录文件的名字、**索引节点指针**以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，**目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存**。

由于索引节点唯一标识一个文件，而目录项记录着文件的名，所以目录项和索引节点的关系是多对一，也就是说，一个文件可以有多个别字。比如，硬链接的实现就是多个目录项中的索引节点指向同一个文件。

> 目录项和目录是一个东西吗?

目录是个文件，持久化存储在磁盘，而目录项是内核一个数据结构，缓存在内存。

> 那文件数据是如何存储在磁盘的呢？

磁盘读写的最小单位是**扇区**，扇区的大小只有 `512B` 大小，很明显，如果每次读写都以这么小为单位，那这读写的效率会非常低。

所以，文件系统把多个扇区组成了一个**逻辑块**，每次读写的最小单位就是逻辑块（数据块），Linux 中的逻辑块大小为 `4KB`，也就是一次性读写 8 个扇区，这将大大提高了磁盘的读写的效率。

![操作系统-image-23](images/操作系统-image-23.png)

另外, 磁盘进行格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区。

- _超级块_，用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。
- _索引节点区_，用来存储索引节点；
- _数据块区_，用来存储文件或目录数据；

我们不可能把超级块和索引节点区全部加载到内存，这样内存肯定撑不住，所以只有当需要使用的时候，才将其加载进内存，它们加载进内存的时机是不同的：

- 超级块：当文件系统挂载时进入内存
- 索引节点区：当文件被访问时进入内存

### 基本概念

> 文件系统主要做了什么?

- **存储管理**：将文件数据存储到物理存储介质中，并且管理空间分配，以确保每个文件都有足够的空间存储，并避免文件之间发生冲突。
- **文件管理**：文件的创建、删除、移动、重命名、压缩、加密、共享等等。
- **目录管理**：目录的创建、删除、移动、重命名等等。
- **文件访问控制**：管理不同用户或进程对文件的访问权限，以确保用户只能访问其被授权访问的文件，以保证文件的安全性和保密性。

> 硬链接和软链接有什么区别

在 Linux/类 Unix 系统上，文件链接（File Link）是一种特殊的文件类型，可以在文件系统中指向另一个文件。常见的文件链接类型有两种：

**1、硬链接（Hard Link）**

- 硬链接通过 inode 节点号建立连接，**硬链接和源文件的 inode 节点号相同，两者对文件系统来说是完全平等的**（可以看作是互为硬链接，源头是同一份文件），删除其中任何一个对另外一个没有影响，可以通过给文件设置硬链接文件来防止重要文件被误删。
- 只有删除了源文件和所有对应的硬链接文件，该文件才会被真正删除。
- 硬链接具有一些限制，不能对目录以及不存在的文件创建硬链接，并且，硬链接也不能跨越文件系统。
- `ln` 命令用于创建硬链接。

**2、软链接（Symbolic Link 或 Symlink）**

- 软链接和源文件的 inode 节点号不同，而是指向一个文件路径。
- 源文件删除后，软链接依然存在，但是指向的是一个无效的文件路径。
- 软连接**类似于 Windows 系统中的快捷方式**。
- 不同于硬链接，可以对目录或者不存在的文件创建软链接，并且，软链接可以跨越文件系统。
- `ln -s` 命令用于创建软链接。

> 硬链接为什么不能跨文件系统?

我们之前提到过，硬链接是通过 inode 节点号建立连接的，而硬链接和源文件共享相同的 inode 节点号。

然而，每个文件系统都有自己的独立 inode 表，且每个 inode 表只维护该文件系统内的 inode。如果在不同的文件系统之间创建硬链接，可能会导致 inode 节点号冲突的问题，即目标文件的 inode 节点号已经在该文件系统中被使用。

> 提高文件系统性能的方式有哪些?

- **优化硬件**：使用高速硬件设备（如 SSD、NVMe）替代传统的机械硬盘，使用 RAID（Redundant Array of Inexpensive Disks）等技术提高磁盘性能。
- **选择合适的文件系统选型**：不同的文件系统具有不同的特性，对于不同的应用场景选择合适的文件系统可以提高系统性能。
- **运用缓存**：访问磁盘的效率比较低，可以运用缓存来减少磁盘的访问次数。不过，需要注意缓存命中率，缓存命中率过低的话，效果太差。
- **避免磁盘过度使用**：注意磁盘的使用率，避免将磁盘用满，尽量留一些剩余空间，以免对文件系统的性能产生负面影响。
- **对磁盘进行合理的分区**：合理的磁盘分区方案，能够使文件系统在不同的区域存储文件，从而减少文件碎片，提高文件读写性能。

> 常见的磁盘调度算法有哪些?

磁盘调度算法是操作系统中对磁盘访问请求进行排序和调度的算法，其目的是提高磁盘的访问效率。

![操作系统-image-24](images/操作系统-image-24.png)

- **先来先服务算法（First-Come First-Served，FCFS）**：按照请求到达磁盘调度器的顺序进行处理，先到达的请求的先被服务。FCFS 算法实现起来比较简单，不存在算法开销。不过，由于没有考虑磁头移动的路径和方向，平均寻道时间较长。同时，该算法**容易出现饥饿问题**，即一些后到的磁盘请求可能需要等待很长时间才能得到服务。
- **最短寻道时间优先算法（Shortest Seek Time First，SSTF）**：也被称为最佳服务优先（Shortest Service Time First，SSTF）算法，优先选择距离当前磁头位置最近的请求进行服务。SSTF 算法**能够最小化磁头的寻道时间**，但容易出现饥饿问题
- **扫描算法（SCAN）**：也被称为电梯（Elevator）算法，基本思想和电梯非常类似。磁头沿着一个方向扫描磁盘，如果经过的磁道有请求就处理，直到到达磁盘的边界，然后改变移动方向，依此往复。SCAN 算法能够保证所有的请求得到服务，解决了饥饿问题。但是，如果磁头从一个方向刚扫描完，请求才到的话。这个请求就需要等到磁头从相反方向过来之后才能得到处理。
- **循环扫描算法（Circular Scan，C-SCAN）**：SCAN 算法的变体，只在磁盘的一侧进行扫描，并且只按照一个方向扫描，直到到达磁盘边界，然后回到磁盘起点，重新开始循环。
- **边扫描边观察算法（LOOK）**：SCAN 算法中磁头到了磁盘的边界才改变移动方向，这样可能会做很多无用功，因为磁头移动方向上可能已经没有请求需要处理了。LOOK 算法对 SCAN 算法进行了改进，如果磁头移动方向上已经没有别的请求，就可以立即改变磁头移动方向，依此往复。也就是边扫描边观察指定方向上还有无请求，因此叫 LOOK。
- **均衡循环扫描算法（C-LOOK）**：C-SCAN 只有到达磁盘边界时才能改变磁头移动方向，并且磁头返回时也需要返回到磁盘起点，这样可能会做很多无用功。C-LOOK 算法对 C-SCAN 算法进行了改进，如果磁头移动的方向上已经没有磁道访问请求了，就可以立即让磁头返回，并且磁头只需要返回到有磁道访问请求的位置即可。

